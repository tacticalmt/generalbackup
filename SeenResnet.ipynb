{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "import os\n",
    "from torch.optim import RMSprop\n",
    "from torchvision.utils import make_grid\n",
    "from pylab import plt\n",
    "import Mod.res_block as resblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数配置\n",
    "#path=os.path.abspath('../../dataset/Animals_with_Attributes2/')\n",
    "tar_path=os.path.abspath('../../dataset/GZSL_for_AWA/Animals_with_Attributes2/')\n",
    "bat_size=32\n",
    "img_size=227\n",
    "gpu=True\n",
    "tr_epoch=2\n",
    "worker=2\n",
    "\n",
    "\n",
    "transform1=transforms.Compose([\n",
    "    transforms.Resize((img_size,img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集载入\n",
    "class SeenData(Dataset):\n",
    "    def __init__(self,root,transforms=None,train_data=True,label=None):\n",
    "        #路径\n",
    "        #self.path=root\n",
    "        \n",
    "        if train_data==True:\n",
    "            #root_label=os.path.abspath('../dataset/Animals_with_Attributes2')\n",
    "            label_path=[x.path for x in os.scandir(root) if 'trainclass' in x.path]\n",
    "            word=[]\n",
    "            for i,file_label in enumerate(label_path):\n",
    "                f=open(file_label,'r')\n",
    "                while True:\n",
    "                    temp_w=f.readline().strip()\n",
    "                    if not temp_w:\n",
    "                        break\n",
    "                    word.append(temp_w)\n",
    "                f.close()\n",
    "            \n",
    "            path_dir=[]\n",
    "            self.label_list=word\n",
    "            for key_word in self.label_list:\n",
    "                [path_dir.append(x.path) for x in os.scandir(root+'/trainingset/') if x.name.endswith(key_word)]\n",
    "                \n",
    "            pic_path=[]\n",
    "            label_t=[]\n",
    "            for l,train_root in enumerate(path_dir):#对训练集文件夹遍历\n",
    "                #[pic_path.append(x.path) for x in os.scandir(train_root) if x.name.endswith(\".jpg\")]#每个文件夹里的图片地址\n",
    "                for x in os.scandir(train_root):\n",
    "                    if x.name.endswith(\".jpg\"):\n",
    "                        pic_path.append(x.path)\n",
    "                        label_t.append(l)\n",
    "                        \n",
    "            #pic_path=path_dir#图片文件夹目录\n",
    "            label_np=np.array(label_t)\n",
    "            label_tensor=torch.from_numpy(label_np).type(torch.LongTensor)\n",
    "            self.images_files=pic_path #图片目录\n",
    "            self.transforms=transforms\n",
    "            self.label=label_tensor\n",
    "            \n",
    "        else:\n",
    "            self.path#测试机读取\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        try:\n",
    "            pic_data=self.transforms(Image.open(self.images_files[index]))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(self.images_files[index])\n",
    "            return self.transforms(Image.open(self.images_files[index-1])),self.label[index]\n",
    "            \n",
    "        else:\n",
    "            return pic_data,self.label[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_files)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络\n",
    "def Conv1(in_planes, places, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_planes,out_channels=places,kernel_size=7,stride=stride,padding=3, bias=False),\n",
    "        nn.BatchNorm2d(places),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 4):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_places,out_channels=places,kernel_size=1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places*self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places*self.expansion),\n",
    "        )\n",
    "\n",
    "        if self.downsampling:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(places*self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bottleneck(x)\n",
    "\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,blocks, num_classes=1000, expansion = 4):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.expansion = expansion\n",
    "\n",
    "        self.conv1 = Conv1(in_planes = 3, places= 64)\n",
    "\n",
    "        self.layer1 = self.make_layer(in_places = 64, places= 64, block=blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(in_places = 256,places=128, block=blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(in_places=512,places=256, block=blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(in_places=1024,places=512, block=blocks[3], stride=2)\n",
    "\n",
    "        #self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048,num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def make_layer(self, in_places, places, block, stride):\n",
    "        layers = []\n",
    "        layers.append(Bottleneck(in_places, places,stride, downsampling =True))\n",
    "        for i in range(1, block):\n",
    "            layers.append(Bottleneck(places*self.expansion, places))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ResNet([3, 4, 23, 3],num_classes=40)\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(params=net.parameters(),lr=0.001)\n",
    "indata=SeenData(tar_path,transform1)\n",
    "data_training=DataLoader(indata,bat_size,shuffle = True,num_workers=worker)\n",
    "#resb=resblock.ResBlock()\n",
    "if gpu:\n",
    "    \n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhaozhi/dataset/GZSL_for_AWA/Animals_with_Attributes2/trainingset/collie/collie_10718.jpg\n",
      "2402.372113466263\n",
      "/home/zhaozhi/dataset/GZSL_for_AWA/Animals_with_Attributes2/trainingset/collie/collie_10718.jpg\n",
      "2076.705848813057\n",
      "[2402.37211347 2076.70584881]\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "Loss=[]\n",
    "for epoch in range(tr_epoch):\n",
    "    training_loss=0.0\n",
    "    for iter_batch,batch in enumerate(data_training):\n",
    "        \n",
    "        data=batch[0]\n",
    "        tar_label=batch[1]\n",
    "        if gpu:\n",
    "            data=data.cuda()\n",
    "            tar_label=tar_label.cuda()\n",
    "        output=net(data)\n",
    "        loss=loss_func(output,tar_label)\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss+= loss.item()# * batch.size(0)\n",
    "        \n",
    "    print(training_loss)\n",
    "    Loss.append(training_loss)\n",
    "        \n",
    "        \n",
    "    if (epoch+1)%400==0:\n",
    "        torch.save(net.state_dict(),'./models/'+str(epoch+1)+'seenResNet.pkl')\n",
    "Loss0 = np.array(Loss)\n",
    "print(Loss0)\n",
    "#torch.save(Loss0,'./models/train_loss.pth')  \n",
    "np.save('./models/train_loss_resnet.npy',Loss0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

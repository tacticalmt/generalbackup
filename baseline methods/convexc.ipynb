{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "import os\n",
    "from torch.optim import RMSprop\n",
    "from torchvision.utils import make_grid\n",
    "from pylab import plt\n",
    "#import Mod.res_block as resblock\n",
    "import Libm.imporfunc as f_semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=os.path.abspath('../../../dataset/GZSL_for_AWA/Animals_with_Attributes2/')\n",
    "path_model=os.path.abspath('../../../dataset/wiki.en.text.model')\n",
    "seman_path=os.path.abspath('../')\n",
    "#vec_model=Word2Vec.load(path_model)#载入语义模型\n",
    "bat_size=32\n",
    "img_size=227\n",
    "gpu=True\n",
    "tr_epoch=5\n",
    "worker=2\n",
    "dim=300\n",
    "\n",
    "transform1=transforms.Compose([\n",
    "    transforms.Resize((img_size,img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集载入\n",
    "#数据集载入\n",
    "class SeenData(Dataset):\n",
    "    def __init__(self,root,transforms=None,train_data=True,label=None):\n",
    "        #路径\n",
    "        #self.path=root\n",
    "        \n",
    "        if train_data==True:\n",
    "            dir_class='trainingset'\n",
    "            #root_label=os.path.abspath('../dataset/Animals_with_Attributes2')\n",
    "        else:\n",
    "            dir_class='testingset'\n",
    "        #seman_dict=np.load(seman_path+'/'+'semantic'+str(dim)+'.npy').item()        \n",
    "        #label_path=[x.path for x in os.scandir(root) if 'trainclass' in x.path]\n",
    "        #word=[]\n",
    "        #for i,file_label in enumerate(label_path):\n",
    "        #    f=open(file_label,'r')\n",
    "        #    while True:\n",
    "        #        temp_w=f.readline().strip()\n",
    "        #        if not temp_w:\n",
    "        #             break\n",
    "        #        word.append(temp_w)\n",
    "        #    f.close()\n",
    "        word=f_semantic.get_name_list(root,cls='trainclass')#地址参数有问题\n",
    "        label_dict=f_semantic.get_dict_name(seman_path)#待修改地址部分参数\n",
    "        cls_dir,info=f_semantic.get_path_info(word,label_dict,data_path)#地址参数有问题\n",
    "        self.images_files,label_t,self.label_list,self.label_train=f_semantic.data_pack(cls_dir,info,vec_model)\n",
    "            \n",
    "        #path_dir=[]\n",
    "        #self.label_list=word\n",
    "        #label_name=[]\n",
    "        #for key_word in self.label_list:\n",
    "         #   print(key_word)\n",
    "         #   [path_dir.append(x.path) for x in os.scandir(root+'/'+dir_class+'/') if x.name.endswith(key_word)]\n",
    "            #用list存对应的类标名称\n",
    "            \n",
    "        #pic_path=[]\n",
    "        #label_t=[]\n",
    "        #for l,train_root in enumerate(path_dir):#对训练集文件夹遍历\n",
    "            #[pic_path.append(x.path) for x in os.scandir(train_root) if x.name.endswith(\".jpg\")]#每个文件夹里的图片地址\n",
    "        #    for x in os.scandir(train_root):\n",
    "        #        if x.name.endswith(\".jpg\"):\n",
    "        #            pic_path.append(x.path)\n",
    "        #            label_t.append(l)\n",
    "                        \n",
    "            #pic_path=path_dir#图片文件夹目录\n",
    "        \n",
    "        \n",
    "        label_np=np.array(label_t)\n",
    "        label_tensor=torch.from_numpy(label_np).type(torch.LongTensor)\n",
    "        #\n",
    "        self.images_files=pic_path #图片目录\n",
    "        self.transforms=transforms\n",
    "        self.label=label_tensor\n",
    "        #添加一个返回semantic的功能，在getitem返回 semantic[index,:]\n",
    "        \n",
    "    def __getitem__(self,index):#返回一个样本的图片地址，训练类标，语义类标，真实类标\n",
    "        try:\n",
    "            pic_data=self.transforms(Image.open(self.images_files[index]))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(self.images_files[index])\n",
    "            return self.transforms(Image.open(self.images_files[index-1])),self.train_label[index],self.seman_label_list[index],self.true_label_list[index]#返回类名\n",
    "            \n",
    "        else:\n",
    "            return pic_data,self.label[index],self.train_label[index],self.seman_label_list[index],self.true_label_list[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_files)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集载入\n",
    "class SeenData(Dataset):\n",
    "    def __init__(self,data_root,seman_dict,transforms=None,data_type='training'):#data_root为总文件夹路径\n",
    "        if data_type=='training':\n",
    "            cls_type='trainclasses'\n",
    "            category='trainingset'\n",
    "        elif data_type=='zsl':\n",
    "            cls_type='testclasses'\n",
    "            category='testingset'\n",
    "        elif data_type=='gzsl':\n",
    "            cls_type='gzslclasses'\n",
    "            category='testingset'\n",
    "        else:\n",
    "            print('no model type')\n",
    "            \n",
    "        word=f_semantic.get_name_list(data_root,cls_type)#地址为包含类名文件txt的文件夹的地址\n",
    "        label_dict=f_semantic.get_dict_name(data_root)#\n",
    "        cls_dir,info=f_semantic.get_path_info(word,label_dict,data_root,category)#是读取训练还是测试集\n",
    "        self.images_files,label_t,self.seman_list,self.label_train=f_semantic.data_pack(cls_dir,info,seman_dict)\n",
    "        label_np=np.array(label_t)\n",
    "        #print(label_t)\n",
    "        #print(label_np)\n",
    "        label_tensor=torch.from_numpy(label_np).type(torch.LongTensor)\n",
    "        #\n",
    "        #self.images_files=pic_path #图片目录\n",
    "        self.transforms=transforms\n",
    "        self.true_label=label_tensor\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        try:\n",
    "            pic_data=self.transforms(Image.open(self.images_files[index]))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(self.images_files[index])\n",
    "            return self.transforms(Image.open(self.images_files[index-1])),self.label_train[index-1],self.seman_list[index-1],self.true_label[index-1]#返回类名\n",
    "            \n",
    "        else:\n",
    "            return pic_data,self.label_train[index],self.seman_list[index],self.true_label[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_files)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语义内嵌读取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzslclasses\n",
      "0\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "#载入网络和通用变量\n",
    "alex=AlexNet(40)\n",
    "alex.load_state_dict(torch.load('../models/74seenCNNremake.pkl'))\n",
    "all_seman_dict=np.load(seman_path+'/'+'semantic'+str(dim)+'.npy',allow_pickle=True).item()\n",
    "indata=SeenData(data_path,all_seman_dict,transform1,data_type='gzsl')#改zsl类型时要改\n",
    "testingdata=DataLoader(indata,bat_size,shuffle = False,num_workers=worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainclasses\n",
      "gzslclasses\n",
      "0.05308086295204097\n",
      "0.946919137047959\n"
     ]
    }
   ],
   "source": [
    "#testing  gzsl\n",
    "#需要准备类标对应的全语义内嵌all_seman\n",
    "#需要准备训练类对应的语义内嵌semantic_vec\n",
    "#网络的输出是softmax 最后跟屏蔽低位后跟语义内嵌做积\n",
    "#if gpu:\n",
    "#    alex.cuda()\n",
    "tlabel_name_list=f_semantic.get_dict_name(data_path)\n",
    "\n",
    "test_label_list=f_semantic.get_name_list(data_path)\n",
    "seman_temp,_=f_semantic.get_semantic(test_label_list,tlabel_name_list,all_seman_dict)#训练类标对应的semantic\n",
    "seman_mat=torch.from_numpy(seman_temp)\n",
    "\n",
    "\n",
    "all_test=f_semantic.get_name_list(data_path,cls='gzslclasses')#zsl的时候testclasses  gzsl为gzslclasses\n",
    "all_seman,tl_index=f_semantic.get_semantic(all_test,tlabel_name_list,all_seman_dict)#测试用的全部的类标对应的semantic\n",
    "#all_seman=torch.from_numpy(all_seman_temp)\n",
    "\n",
    "error_rate=0\n",
    "total_samp=0#总样本数\n",
    "error_sam=0\n",
    "T=10#取前几名\n",
    "total_cls=40\n",
    "set_zero=total_cls-T#置零的位数\n",
    "softm=nn.Softmax(dim=1)\n",
    "for i_batch,batch in enumerate(testingdata):\n",
    "    data=batch[0]\n",
    "    train_label=batch[1]\n",
    "    semantic_label=batch[2]\n",
    "    true_label=batch[3]\n",
    "    true_sample_label=true_label.numpy()\n",
    "#    if gpu:\n",
    "#        data=data.cuda()\n",
    "    output=alex(data)\n",
    "    soft_out=softm(output)\n",
    "    #print(output)#缺softmax\n",
    "    #print(soft_out)\n",
    "    index_soft=torch.argsort(soft_out,dim=1)\n",
    "    for i_samp in range(index_soft.size()[0]):\n",
    "        for i_dim in range(set_zero):#把小的值都屏蔽了\n",
    "            soft_out[i_samp,index_soft[i_samp,i_dim]]=0\n",
    "    #print(soft_out)\n",
    "    result_semanti=torch.matmul(soft_out,seman_mat)#output*semantic_vec#semantic_label是样本类标的semantic，每一列维度个数为训练时类别的个数，应该为bat_size*40  40* 300的两个矩阵\n",
    "    np_semantic=result_semanti.detach().numpy()\n",
    "    loc_acc,correct_t,num_s_temp=f_semantic.zsl_el(all_seman,np_semantic,true_sample_label,tl_index,p=1)#结果与全部的semantic做cos距离计算。\n",
    "    #print(loc_acc)\n",
    "    error_sam=error_sam+correct_t#计算累计错误样本\n",
    "    total_samp=total_samp+num_s_temp#总样本个数\n",
    "    \n",
    "acc=error_sam/total_samp#正确率\n",
    "f_acc=1-acc#正确率\n",
    "print(acc)\n",
    "print(f_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#testing zsl\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
